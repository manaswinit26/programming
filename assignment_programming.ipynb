{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manaswinit26/programming/blob/main/assignment_programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c24d5d-9973-45a1-83be-8bca8b03e576",
      "metadata": {
        "id": "f7c24d5d-9973-45a1-83be-8bca8b03e576"
      },
      "source": [
        "# Assignment: Programming Review\n",
        "## Do Q1 and one other question."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3fb7b5-0345-447d-840a-59f667fe9c0c",
      "metadata": {
        "id": "4a3fb7b5-0345-447d-840a-59f667fe9c0c"
      },
      "source": [
        "**Q1.** First, think about your priorities in life. What kind of salary do you want to make after graduation? Do you mind getting more schooling? What kind of work-life balance are you looking for? Where do you want to work, geographically? You don't have to write this down here, just think about it.\n",
        "\n",
        "1. Go to the Occupational Outlook Handbook at [https://www.bls.gov/ooh/](https://www.bls.gov/ooh/). Look up \"Data Scientist.\" Read about the job and start collecting data about it from the job profile (e.g. salary, education required, work setting)\n",
        "2. Find 7-10 other jobs that appeal to you, and collect the same data as you did for Data Scientist. Put it all in a spreadsheet.\n",
        "3. Do any of your findings surprise you?\n",
        "4. Rank the jobs you picked from best to worst, and briefly explain why you did so.\n",
        "5. Please submit your spreadsheet with the assignment --- you can \"de-identify\" it and remove anything that you find personally identifying or you don't want to share, of course. We'll play with these data later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9d65ad-3740-43d3-a944-b3653fbeb80c",
      "metadata": {
        "id": "7e9d65ad-3740-43d3-a944-b3653fbeb80c"
      },
      "source": [
        "Depends on student opinions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Data Scientist**   \n",
        "     - Yearly Salary: $100,910\n",
        "     - Hourly Salary: $48.52\n",
        "     - Typical Education Requirement: Bachelor's degree\n",
        "     - Job Outlook, 2021-31: 36%\n",
        "     - Work Environment: Office\n",
        "\n",
        "\n",
        "2. **Job Data** (spread sheet linked)\n",
        "    - https://docs.google.com/spreadsheets/d/1nqzp1mdmxorr4jepBz9rqsMMqM8I74tqVxNoqw7CUKI/edit?usp=sharing\n",
        "\n",
        "3. **Findings**\n",
        "    - Yes, some of the findings suprised me. I did not know that it is possible to be an economist/statistician/mathematician without a PHD. I also expected Market Research Analysts to have a higher salary.\n",
        "\n",
        "4. **Rankings**\n",
        "   1. Data Scientist\n",
        "   2. Financial Analyst\n",
        "   3. Computer and Information Research Scientist\n",
        "   4. Software Developer, Quality Assurance Analysts, and Testers\n",
        "   5. Actuary\n",
        "   6. Market Research Analyst\n",
        "   7. Mathematicians/Statisticans\n",
        "   8. Economist\n",
        "\n",
        "My rankings were based on yearly salary in comparison to education required. I ranked the jobs that recommend a PHD at the bottom since they have similar salaries to jobs that only require a Bachelor's degree. I also used my own personal preferences as I am interested in data science/analysis jobs."
      ],
      "metadata": {
        "id": "6K0_h2LaaasK"
      },
      "id": "6K0_h2LaaasK"
    },
    {
      "cell_type": "markdown",
      "id": "ab57312f-fd41-4763-b38c-3b7c1b062b1c",
      "metadata": {
        "id": "ab57312f-fd41-4763-b38c-3b7c1b062b1c"
      },
      "source": [
        "**Q3.** This is a basic review of some statistics along with practice writing functions. Like we talked about, Python is a general purpose programming language and ships without basic data handling or statistical packages coded in. The beginning of the code chunk below generates random values for you to test your work on; since the random values are generates as NumPy arrays, you'll need to use the Numpy methods `np.sum(x)` to sum the vector $x$ and `np.sqrt(x)` to take the square roots of the values in $x$, as well as the Python function `len(x)` to get the length of $x$.\n",
        "\n",
        "Try to reuse the functions you've already defined as you work through the following questions, rather than rewriting code you've already written.\n",
        "\n",
        "1. Write a function that computes the **sample average** or **mean** of a vector $x$,\n",
        "$$\n",
        "\\bar{x} = \\dfrac{x_1 + x_2 + ... + x_N}{N} = \\dfrac{\\sum_{i=1}^N x_i}{N}.\n",
        "$$\n",
        "Write a function in the code chunk below to compute this quantity, and then use it to compute the mean of $x$.\n",
        "2. Write a function that computes the **sample standard deviation** of a vector $x$,\n",
        "$$\n",
        "s_x = \\sqrt{\\dfrac{(x_1 - \\bar{x})^2 + ... (x_N - \\bar{x})^2 }{N-1}} = \\sqrt{\\dfrac{ \\sum_{i=1}^N (x_i - \\bar{x})^2 }{N-1}}.\n",
        "$$\n",
        "The intuition of this quantity is that it computes roughly the average distance from each point $x_i$ to the sample mean $\\bar{x}$. If it is small, it means all the points are clustered tightly around the mean, and if it is large, it means the points are typically far away from the average. Write a function in the code chunk below to compute this quantity, and then use it to compute the sample standard deviation of $x$.\n",
        "3. Write a function that calls the previous two to **standardize** the values of the vector as a **$z$-score**:\n",
        "$$\n",
        "z = \\dfrac{x-\\bar{x}}{s}.\n",
        "$$\n",
        "The intuition of this quantity is that it is recentering all the values of $x$ so the average is zero and then scaling them by the standard deviation. If the data are normally distributed and $N$ is large, the $z$ score will approximately follow a standard normal distribution. Write a function in the code chunk below to compute this quantity, and then use it to compute the z-scores for $x$.\n",
        "4. The **sample covariance** of two vectors $x=(x_1,...,x_N)$ and $y=(y_1,...,y_N)$ is defined as\n",
        "$$\n",
        "cov(x,y) = \\dfrac{(x_1 - \\bar{x})(y_1-\\bar{y}) + (x_2 - \\bar{x})(y_2-\\bar{y}) + ... + (x_N - \\bar{x})(y_{N}-\\bar{y})}{N-1}\n",
        "$$\n",
        "$$\n",
        "= \\dfrac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{N-1}.\n",
        "$$\n",
        "The intuition of this quantity is that it looks at the pairs $(x_i, y_i)$ and compares them to the means $(\\bar{x},\\bar{y})$ to determine whether $x$ and $y$ tend to co-vary in the same direction relative to their means: If the values of $x$ and $y$ are typically both above or below the mean values of $x$ and $y$, then $x$ and $y$ will have a positive covariance, but if $x$ is typically above the mean of $x$ when $y$ is typically below the mean of $y$ or vice versa, then they will have a negative covariance. Write a function in the code chunk below to compute this quantity, and then use it to compute the covariance of the generated $x$ and $y$.\n",
        "6. The **sample correlation coefficient** of two vectors $x$ and $y$ is defined as\n",
        "$$\n",
        "r_{xy} = \\dfrac{cov(x,y)}{s_x s_y}\n",
        "$$\n",
        "Use your functions to create a new function that compute this quantity. The intuition of this quantity is that it is like the covariance, but normalized so that its values like between -1 and 1: perfect negative linear association between the variables at -1, no association at 0, and perfect positive linear association between the variables at 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f42ab788-af0c-47a4-a103-46c9a37bfad3",
      "metadata": {
        "id": "f42ab788-af0c-47a4-a103-46c9a37bfad3",
        "outputId": "09d72289-0912-4b3d-8c78-bcad0f4b8c18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: -1.0899806430403438\n",
            "Sample Standard Deviation: 3.2847981697718236\n",
            "Z-score: [ 1.65529743e+00 -1.05060967e+00 -7.45764027e-01 -3.81605317e-01\n",
            "  2.46819081e-01  5.21899218e-01  7.09402280e-01 -5.93065755e-01\n",
            "  7.04895922e-01  1.96679707e-01 -1.11094417e+00  8.52210438e-02\n",
            "  4.83567023e-02 -3.54864746e-01  3.29284367e-01 -4.56556204e-01\n",
            "  8.63353457e-01 -7.31944166e-01 -1.36789260e+00  9.92808655e-01\n",
            "  3.80557712e-01 -1.00449055e-01 -1.47448781e+00  9.74866813e-01\n",
            "  1.75714872e+00  9.77807320e-01  7.01655902e-01  3.08432853e-02\n",
            "  1.04345868e+00 -7.77329859e-02  8.17286639e-01 -1.81985598e-01\n",
            "  1.27893480e+00 -3.73468531e-01 -1.17167890e+00  1.74144344e+00\n",
            "  1.86784228e-01 -1.89565093e+00 -9.00401357e-01 -7.08862478e-01\n",
            " -4.51955816e-01  1.60336282e+00 -5.82237516e-01 -6.40780869e-02\n",
            "  3.06059108e-01  1.62147565e+00 -1.72034611e+00 -1.60534914e+00\n",
            "  9.59582964e-02 -2.99937996e-01  1.32234333e+00  2.68497173e+00\n",
            "  1.60195630e-01 -8.62816506e-02 -4.04496901e-01  1.20207672e+00\n",
            "  1.70429319e-01  1.01659241e-01 -1.24957962e+00  1.74652093e+00\n",
            "  1.80610510e+00  1.05578040e+00 -4.26312719e-02 -8.22571369e-01\n",
            " -6.19855088e-01  1.12643962e+00 -9.39857919e-01  1.08155913e+00\n",
            "  1.39289760e+00 -5.53628814e-01  1.16220669e+00 -7.54433847e-01\n",
            " -1.89042558e+00  7.28233679e-01 -2.13581711e-01 -2.05476861e+00\n",
            " -3.34916456e-01  8.53764627e-02 -1.63448147e+00 -9.93158172e-01\n",
            " -7.21895158e-02 -9.62591398e-01 -1.99169857e+00  9.91739531e-02\n",
            "  1.80837540e+00 -5.74516696e-01 -3.06457077e-01  5.33852860e-01\n",
            " -4.42142862e-01  1.29239653e-01  4.43289273e-01 -5.65744407e-01\n",
            " -1.12100487e+00  5.38394279e-01 -5.43433602e-01 -1.45451441e+00\n",
            " -6.04992581e-01  5.62381871e-01  3.84576556e-01  8.74307726e-01\n",
            " -6.91036907e-01 -5.86959378e-01  1.95614958e-01 -1.55327186e+00\n",
            " -2.96837962e-01 -5.16891724e-01 -6.80975102e-01 -5.00058414e-01\n",
            " -3.81731719e-01 -7.49877821e-01  1.30345247e+00 -2.56837973e-01\n",
            "  2.30019290e-02  5.62752389e-01 -1.01689732e+00  9.55520653e-01\n",
            "  3.63461330e-01 -1.70577720e-01 -7.92649134e-01  1.98164085e+00\n",
            "  4.14437622e-01  5.31871413e-01 -7.66075184e-01 -8.52795489e-01\n",
            " -1.36550487e+00  4.53881084e-01 -1.22244693e+00  2.25563767e-01\n",
            " -2.20868409e+00  4.30329087e-01 -7.05522036e-01 -1.19976928e+00\n",
            "  1.28578471e+00  2.13849637e-01  6.68780404e-01  3.05301882e-01\n",
            " -3.97281999e-01 -6.84439141e-01  2.07934996e+00  3.76747050e-01\n",
            "  1.46326954e-01 -1.62487242e+00  3.92169258e-01  2.85474051e-01\n",
            "  9.58078099e-02 -1.57915815e+00 -8.85879688e-01 -3.03193046e-01\n",
            " -2.67118360e-01  1.74067126e+00  5.06006174e-01 -2.14202910e+00\n",
            " -1.20167540e+00 -1.68370272e+00 -6.30625680e-01 -4.69870625e-01\n",
            " -5.06033885e-02 -1.52511690e+00  2.23580423e-01  3.22191164e-01\n",
            " -7.46501277e-01  1.25556027e+00 -1.13154811e+00  1.09002644e+00\n",
            " -3.11424110e-01  3.80285457e-01  9.34761921e-01  8.97531640e-01\n",
            "  3.08076263e-01 -2.78941998e+00 -3.46388167e-01 -5.83720647e-01\n",
            "  1.73727245e-01  1.13508701e-01  1.66047968e+00  1.06033336e+00\n",
            " -3.40329313e-01 -7.88609506e-01 -1.38060678e+00 -3.92061706e-01\n",
            "  2.40978171e-01  1.09127407e-01 -4.61240403e-01  4.94741716e-01\n",
            "  1.97972745e+00  1.34455722e+00  1.75421818e+00  1.14674906e+00\n",
            "  1.08096701e+00 -2.94861751e-01 -7.20383713e-01  1.44460597e+00\n",
            "  1.82905529e+00  4.20105328e-01  5.68995033e-01  1.48421475e-01\n",
            "  2.99707746e-01 -1.77741458e-02  2.00910916e+00  6.86685548e-04]\n",
            "Covariance: -2.8396505928938773\n",
            "Correlation Coefficient: -0.42205093921264875\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math as math\n",
        "np.random.seed(100) # Set the seed for the random number generator\n",
        "rho, sigma_x, sigma_y = -.4, 3, 2 # Variance-Covariance Parameters\n",
        "vcv = np.array([[sigma_x**2, rho*sigma_x*sigma_y],\n",
        "                [rho*sigma_x*sigma_y,sigma_y**2]]) # VCV Matrix\n",
        "mu = np.array([-1,2]) # Population averages\n",
        "sample = np.random.multivariate_normal(mu,vcv,200) # Multivariate normal draws\n",
        "x = sample[:,0]\n",
        "y = sample[:,1]\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "def mean(x):\n",
        "  sm = np.sum(x) / len(x)\n",
        "  return sm\n",
        "print(\"Sample Mean:\", mean(x))\n",
        "\n",
        "def sd(x):\n",
        "  m = mean(x)\n",
        "  l = len(x)\n",
        "  d = (x-m)**2\n",
        "  s = np.sum(d)\n",
        "  n = s/(l-1)\n",
        "  sq = np.sqrt(n)\n",
        "  return sq\n",
        "print(\"Sample Standard Deviation:\" , sd(x))\n",
        "\n",
        "\n",
        "def z(x):\n",
        "  std = sd(x)\n",
        "  m = mean(x)\n",
        "  zscore = (x-m)/std\n",
        "  return zscore\n",
        "print(\"Z-score:\", z(x))\n",
        "\n",
        "def cov(x, y):\n",
        "  meanx = mean(x)\n",
        "  meany = mean(y)\n",
        "  diffx = x - mean(x)\n",
        "  diffy = y - mean(y)\n",
        "  sumdiffs = np.sum(diffx * diffy)\n",
        "  covar = sumdiffs/ (len(x) -1)\n",
        "  return (covar)\n",
        "print(\"Covariance:\", cov(x, y))\n",
        "\n",
        "\n",
        "def corr(x, y):\n",
        "  covar = cov(x, y)\n",
        "  sdx = sd(x)\n",
        "  sdy = sd(y)\n",
        "  corrcoef = covar / (sdx * sdy)\n",
        "  return (corrcoef)\n",
        "print(\"Correlation Coefficient:\", corr(x, y))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}